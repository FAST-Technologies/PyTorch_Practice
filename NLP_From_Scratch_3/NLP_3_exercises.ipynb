{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SOS_token: int = 0\n",
    "EOS_token: int = 1\n",
    "\n",
    "# ===============================\n",
    "# DATA PREPARATION\n",
    "# ===============================\n",
    "\n",
    "class Lang:\n",
    "    \"\"\"Language vocabulary class for word-to-index mapping.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str) -> None:\n",
    "        self.name: str = name\n",
    "        self.word2index: Dict[str, int] = {}\n",
    "        self.word2count: Dict[str, int] = {}\n",
    "        self.index2word: Dict[int, str] = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words: int = 2\n",
    "    \n",
    "    def addSentence(self, sentence: str) -> None:\n",
    "        \"\"\"Add all words in a sentence to the vocabulary.\"\"\"\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "    \n",
    "    def addWord(self, word: str) -> None:\n",
    "        \"\"\"Add a word to the vocabulary.\"\"\"\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ],
   "id": "1f3f2c1e3025a881"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def unicodeToAscii(s: str) -> str:\n",
    "    \"\"\"Turn a Unicode string to plain ASCII.\"\"\"\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "\n",
    "def normalizeString(s: str) -> str:\n",
    "    \"\"\"Lowercase, trim, and remove non-letter characters.\"\"\"\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "def readLangs(lang1: str, lang2: str, reverse: bool = False) -> Tuple[Lang, Lang, List[List[str]]]:\n",
    "    \"\"\"Read language pairs from file.\"\"\"\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    lines: List[str] = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    \n",
    "    pairs: List[List[str]] = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang: Lang = Lang(lang2)\n",
    "        output_lang: Lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    \n",
    "    return input_lang, output_lang, pairs"
   ],
   "id": "90de32871de2c28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "MAX_LENGTH: int = 10\n",
    "\n",
    "eng_prefixes: Tuple[str, ...] = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p: List[str]) -> bool:\n",
    "    \"\"\"Check if a pair meets filtering criteria.\"\"\"\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs: List[List[str]]) -> List[List[str]]:\n",
    "    \"\"\"Filter pairs based on length and prefix criteria.\"\"\"\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "\n",
    "def prepareData(lang1: str, lang2: str, reverse: bool = False) -> Tuple[Lang, Lang, List[List[str]]]:\n",
    "    \"\"\"Prepare data by reading, filtering, and building vocabulary.\"\"\"\n",
    "    input_lang: Lang\n",
    "    output_lang: Lang\n",
    "    pairs: List[List[str]]\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ],
   "id": "45d28fab8dfb08d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===============================\n",
    "# PRETRAINED EMBEDDINGS\n",
    "# ===============================\n",
    "\n",
    "def load_pretrained_embeddings(\n",
    "    lang: Lang,\n",
    "    embedding_file: str,\n",
    "    embedding_dim: int = 300\n",
    ") -> Optional[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Load pretrained embeddings (GloVe format).\n",
    "    \n",
    "    Expected format: word dim1 dim2 ... dimN\n",
    "    Example: the 0.418 0.24968 -0.41242 ...\n",
    "    \"\"\"\n",
    "    embeddings: Dict[str, List[float]] = {}\n",
    "    \n",
    "    try:\n",
    "        with open(embedding_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                embeddings[word] = vector\n",
    "        \n",
    "        print(f\"Loaded {len(embeddings)} word vectors\")\n",
    "        \n",
    "        # Create embedding matrix\n",
    "        embedding_matrix = np.random.randn(lang.n_words, embedding_dim).astype(np.float32)\n",
    "        embedding_matrix *= 0.01  # Small random initialization\n",
    "        \n",
    "        # Fill in pretrained embeddings\n",
    "        found = 0\n",
    "        for word, idx in lang.word2index.items():\n",
    "            if word in embeddings:\n",
    "                embedding_matrix[idx] = embeddings[word]\n",
    "                found += 1\n",
    "        \n",
    "        print(f\"Found pretrained embeddings for {found}/{lang.n_words} words\")\n",
    "        \n",
    "        return torch.from_numpy(embedding_matrix)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Pretrained embeddings file not found: {embedding_file}\")\n",
    "        print(\"Using random initialization instead\")\n",
    "        return None"
   ],
   "id": "7735d941e5b7decc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===============================\n",
    "# MODEL ARCHITECTURES\n",
    "# ===============================\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"Encoder RNN with embedding and GRU.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        dropout_p: float = 0.1,\n",
    "        pretrained_embeddings: Optional[torch.Tensor] = None\n",
    "    ) -> None:\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size: int = hidden_size\n",
    "        \n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding: nn.Embedding = nn.Embedding.from_pretrained(\n",
    "                pretrained_embeddings,\n",
    "                freeze=False  # Allow fine-tuning\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        self.gru: nn.GRU = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout: nn.Dropout = nn.Dropout(dropout_p)\n",
    "    \n",
    "    def forward(self, input: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        embedded: torch.Tensor = self.dropout(self.embedding(input))\n",
    "        output: torch.Tensor\n",
    "        hidden: torch.Tensor\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ],
   "id": "4bf5dd96f62df539"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class DeepEncoderRNN(nn.Module):\n",
    "    \"\"\"Deep encoder with multiple GRU layers.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        n_layers: int = 2,\n",
    "        dropout_p: float = 0.1,\n",
    "        pretrained_embeddings: Optional[torch.Tensor] = None\n",
    "    ) -> None:\n",
    "        super(DeepEncoderRNN, self).__init__()\n",
    "        self.hidden_size: int = hidden_size\n",
    "        self.n_layers: int = n_layers\n",
    "        \n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding: nn.Embedding = nn.Embedding.from_pretrained(\n",
    "                pretrained_embeddings,\n",
    "                freeze=False\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        self.gru: nn.GRU = nn.GRU(\n",
    "            hidden_size,\n",
    "            hidden_size,\n",
    "            num_layers=n_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout_p if n_layers > 1 else 0\n",
    "        )\n",
    "        self.dropout: nn.Dropout = nn.Dropout(dropout_p)\n",
    "    \n",
    "    def forward(self, input: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        embedded: torch.Tensor = self.dropout(self.embedding(input))\n",
    "        output: torch.Tensor\n",
    "        hidden: torch.Tensor\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ],
   "id": "8a8ff674023afdef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"Bahdanau attention mechanism.\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size: int) -> None:\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa: nn.Linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua: nn.Linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va: nn.Linear = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, query: torch.Tensor, keys: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        scores: torch.Tensor = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "        \n",
    "        weights: torch.Tensor = F.softmax(scores, dim=-1)\n",
    "        context: torch.Tensor = torch.bmm(weights, keys)\n",
    "        \n",
    "        return context, weights"
   ],
   "id": "9b5bdaceac707777"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    \"\"\"Decoder RNN with Bahdanau attention.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "        dropout_p: float = 0.1,\n",
    "        pretrained_embeddings: Optional[torch.Tensor] = None\n",
    "    ) -> None:\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding: nn.Embedding = nn.Embedding.from_pretrained(\n",
    "                pretrained_embeddings,\n",
    "                freeze=False\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        \n",
    "        self.attention: BahdanauAttention = BahdanauAttention(hidden_size)\n",
    "        self.gru: nn.GRU = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out: nn.Linear = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout: nn.Dropout = nn.Dropout(dropout_p)\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        encoder_outputs: torch.Tensor,\n",
    "        encoder_hidden: torch.Tensor,\n",
    "        target_tensor: Optional[torch.Tensor] = None\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        batch_size: int = encoder_outputs.size(0)\n",
    "        decoder_input: torch.Tensor = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden: torch.Tensor = encoder_hidden\n",
    "        decoder_outputs: List[torch.Tensor] = []\n",
    "        attentions: List[torch.Tensor] = []\n",
    "        \n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output: torch.Tensor\n",
    "            attn_weights: torch.Tensor\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "            \n",
    "            if target_tensor is not None:\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "            else:\n",
    "                _: torch.Tensor\n",
    "                topi: torch.Tensor\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()\n",
    "        \n",
    "        decoder_outputs_cat: torch.Tensor = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs_cat = F.log_softmax(decoder_outputs_cat, dim=-1)\n",
    "        attentions_cat: torch.Tensor = torch.cat(attentions, dim=1)\n",
    "        \n",
    "        return decoder_outputs_cat, decoder_hidden, attentions_cat\n",
    "    \n",
    "    def forward_step(\n",
    "        self,\n",
    "        input: torch.Tensor,\n",
    "        hidden: torch.Tensor,\n",
    "        encoder_outputs: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        embedded: torch.Tensor = self.dropout(self.embedding(input))\n",
    "        \n",
    "        query: torch.Tensor = hidden.permute(1, 0, 2)\n",
    "        context: torch.Tensor\n",
    "        attn_weights: torch.Tensor\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru: torch.Tensor = torch.cat((embedded, context), dim=2)\n",
    "        \n",
    "        output: torch.Tensor\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "        \n",
    "        return output, hidden, attn_weights"
   ],
   "id": "694afc512face7df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class DeepAttnDecoderRNN(nn.Module):\n",
    "    \"\"\"Deep decoder with multiple layers and attention.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "        n_layers: int = 2,\n",
    "        dropout_p: float = 0.1,\n",
    "        pretrained_embeddings: Optional[torch.Tensor] = None\n",
    "    ) -> None:\n",
    "        super(DeepAttnDecoderRNN, self).__init__()\n",
    "        self.n_layers: int = n_layers\n",
    "        \n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding: nn.Embedding = nn.Embedding.from_pretrained(\n",
    "                pretrained_embeddings,\n",
    "                freeze=False\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        \n",
    "        self.attention: BahdanauAttention = BahdanauAttention(hidden_size)\n",
    "        self.gru: nn.GRU = nn.GRU(\n",
    "            2 * hidden_size,\n",
    "            hidden_size,\n",
    "            num_layers=n_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout_p if n_layers > 1 else 0\n",
    "        )\n",
    "        self.out: nn.Linear = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout: nn.Dropout = nn.Dropout(dropout_p)\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        encoder_outputs: torch.Tensor,\n",
    "        encoder_hidden: torch.Tensor,\n",
    "        target_tensor: Optional[torch.Tensor] = None\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        batch_size: int = encoder_outputs.size(0)\n",
    "        decoder_input: torch.Tensor = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        \n",
    "        # Expand encoder hidden for multiple layers\n",
    "        if encoder_hidden.size(0) != self.n_layers:\n",
    "            decoder_hidden = encoder_hidden.repeat(self.n_layers, 1, 1)\n",
    "        else:\n",
    "            decoder_hidden = encoder_hidden\n",
    "        \n",
    "        decoder_outputs: List[torch.Tensor] = []\n",
    "        attentions: List[torch.Tensor] = []\n",
    "        \n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output: torch.Tensor\n",
    "            attn_weights: torch.Tensor\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "            \n",
    "            if target_tensor is not None:\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "            else:\n",
    "                _: torch.Tensor\n",
    "                topi: torch.Tensor\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()\n",
    "        \n",
    "        decoder_outputs_cat: torch.Tensor = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs_cat = F.log_softmax(decoder_outputs_cat, dim=-1)\n",
    "        attentions_cat: torch.Tensor = torch.cat(attentions, dim=1)\n",
    "        \n",
    "        return decoder_outputs_cat, decoder_hidden, attentions_cat\n",
    "    \n",
    "    def forward_step(\n",
    "        self,\n",
    "        input: torch.Tensor,\n",
    "        hidden: torch.Tensor,\n",
    "        encoder_outputs: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        embedded: torch.Tensor = self.dropout(self.embedding(input))\n",
    "        \n",
    "        # Use last layer's hidden state for attention\n",
    "        query: torch.Tensor = hidden[-1:].permute(1, 0, 2)\n",
    "        context: torch.Tensor\n",
    "        attn_weights: torch.Tensor\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru: torch.Tensor = torch.cat((embedded, context), dim=2)\n",
    "        \n",
    "        output: torch.Tensor\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "        \n",
    "        return output, hidden, attn_weights"
   ],
   "id": "e9f1dee7fb063e63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===============================\n",
    "# TRAINING & EVALUATION\n",
    "# ===============================\n",
    "\n",
    "def get_dataloader(batch_size: int, lang1: str = 'eng', lang2: str = 'fra', reverse: bool = False) -> Tuple[Lang, Lang, DataLoader]:\n",
    "    \"\"\"Create DataLoader for training.\"\"\"\n",
    "    input_lang_local: Lang\n",
    "    output_lang_local: Lang\n",
    "    pairs_local: List[List[str]]\n",
    "    input_lang_local, output_lang_local, pairs_local = prepareData(lang1, lang2, reverse=True)\n",
    "    \n",
    "    n: int = len(pairs_local)\n",
    "    input_ids: npt.NDArray[np.int32] = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids: npt.NDArray[np.int32] = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    \n",
    "    for idx, (inp, tgt) in enumerate(pairs_local):\n",
    "        inp_ids: List[int] = [input_lang_local.word2index[word] for word in inp.split(' ')]\n",
    "        tgt_ids: List[int] = [output_lang_local.word2index[word] for word in tgt.split(' ')]\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "    \n",
    "    train_data: TensorDataset = TensorDataset(\n",
    "        torch.LongTensor(input_ids).to(device),\n",
    "        torch.LongTensor(target_ids).to(device)\n",
    "    )\n",
    "    \n",
    "    train_sampler: RandomSampler = RandomSampler(train_data)\n",
    "    train_dataloader: DataLoader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang_local, output_lang_local, train_dataloader"
   ],
   "id": "95759e4bbc5edda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_epoch(\n",
    "    dataloader: DataLoader,\n",
    "    encoder: nn.Module,\n",
    "    decoder: nn.Module,\n",
    "    encoder_optimizer: optim.Optimizer,\n",
    "    decoder_optimizer: optim.Optimizer,\n",
    "    criterion: nn.Module\n",
    ") -> float:\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    total_loss: float = 0.0\n",
    "    for data in dataloader:\n",
    "        input_tensor: torch.Tensor\n",
    "        target_tensor: torch.Tensor\n",
    "        input_tensor, target_tensor = data\n",
    "        \n",
    "        if encoder_optimizer:\n",
    "            encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        encoder_outputs: torch.Tensor\n",
    "        encoder_hidden: torch.Tensor\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs: torch.Tensor\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "        \n",
    "        loss: torch.Tensor = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        if encoder_optimizer:\n",
    "            torch.nn.utils.clip_grad_norm_(encoder.parameters(), 1.0)\n",
    "            encoder_optimizer.step()\n",
    "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), 1.0)\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n"
   ],
   "id": "471b2b526cb23e07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(\n",
    "    train_dataloader: DataLoader,\n",
    "    encoder: nn.Module,\n",
    "    decoder: nn.Module,\n",
    "    n_epochs: int,\n",
    "    learning_rate: float = 0.001,\n",
    "    print_every: int = 10\n",
    ") -> List[float]:\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    start: float = time.time()\n",
    "    losses: List[float] = []\n",
    "    \n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate) if train_encoder else None\n",
    "    decoder_optimizer: optim.Adam = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion: nn.NLLLoss = nn.NLLLoss()\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss: float = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            elapsed = time.time() - start\n",
    "            print(f'Epoch {epoch}/{n_epochs} ({epoch/n_epochs*100:.0f}%) - Loss: {loss:.4f} - Time: {elapsed:.0f}s')\n",
    "    \n",
    "    return losses\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    encoder: nn.Module,\n",
    "    decoder: nn.Module,\n",
    "    sentence: str,\n",
    "    input_lang: Lang,\n",
    "    output_lang: Lang\n",
    ") -> Tuple[List[str], Optional[torch.Tensor]]:\n",
    "    \"\"\"Evaluate a single sentence.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        indexes: List[int] = [input_lang.word2index[word] for word in sentence.split(' ') if word in input_lang.word2index]\n",
    "        indexes.append(EOS_token)\n",
    "        input_tensor: torch.Tensor = torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "        \n",
    "        encoder_outputs: torch.Tensor\n",
    "        encoder_hidden: torch.Tensor\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs: torch.Tensor\n",
    "        decoder_attn: Optional[torch.Tensor]\n",
    "        decoder_outputs, _, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "        \n",
    "        _: torch.Tensor\n",
    "        topi: torch.Tensor\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids: torch.Tensor = topi.squeeze()\n",
    "        \n",
    "        decoded_words: List[str] = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    \n",
    "    return decoded_words, decoder_attn"
   ],
   "id": "50c4d47e2230d7f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate_bleu(\n",
    "    encoder: nn.Module,\n",
    "    decoder: nn.Module,\n",
    "    pairs: List[List[str]],\n",
    "    input_lang: Lang,\n",
    "    output_lang: Lang,\n",
    "    n: int = 100\n",
    ") -> float:\n",
    "    total_bleu = 0.0\n",
    "    for _ in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        reference = [pair[1].split()]\n",
    "        candidate = output_words[:-1]  # Remove <EOS>\n",
    "        total_bleu += sentence_bleu(reference, candidate, smoothing_function=SmoothingFunction().method1)\n",
    "    return total_bleu / n"
   ],
   "id": "58c67298f9562d63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===============================\n",
    "# EXPERIMENTS\n",
    "# ===============================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT 1: Baseline (Original Architecture)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(32)\n",
    "\n",
    "encoder1 = EncoderRNN(input_lang.n_words, 128).to(device)\n",
    "decoder1 = AttnDecoderRNN(128, output_lang.n_words).to(device)\n",
    "\n",
    "losses1 = train(train_dataloader, encoder1, decoder1, 50, learning_rate=0.001, print_every=10)\n",
    "\n",
    "encoder1.eval()\n",
    "decoder1.eval()\n",
    "\n",
    "# Test\n",
    "test_sentences = [\n",
    "    'je suis trop fatigue',\n",
    "    'il est tres grand',\n",
    "    'elle est belle'\n",
    "]\n",
    "\n",
    "print(\"\\nTest Results (Baseline):\")\n",
    "for sentence in test_sentences:\n",
    "    output_words, _ = evaluate(encoder1, decoder1, sentence, input_lang, output_lang)\n",
    "    print(f\"  {sentence} -> {' '.join(output_words)}\")"
   ],
   "id": "c757e8de894b92fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT 2: Deeper Network (2 layers)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "encoder2 = DeepEncoderRNN(input_lang.n_words, 128, n_layers=2).to(device)\n",
    "decoder2 = DeepAttnDecoderRNN(128, output_lang.n_words, n_layers=2).to(device)\n",
    "\n",
    "losses2 = train(train_dataloader, encoder2, decoder2, 50, learning_rate=0.001, print_every=10)\n",
    "\n",
    "encoder2.eval()\n",
    "decoder2.eval()\n",
    "\n",
    "print(\"\\nTest Results (Deep Network):\")\n",
    "for sentence in test_sentences:\n",
    "    output_words, _ = evaluate(encoder2, decoder2, sentence, input_lang, output_lang)\n",
    "    print(f\"  {sentence} -> {' '.join(output_words)}\")"
   ],
   "id": "24e206adb5e784a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT 3: Larger Hidden Size (256)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "encoder3 = EncoderRNN(input_lang.n_words, 256).to(device)\n",
    "decoder3 = AttnDecoderRNN(256, output_lang.n_words).to(device)\n",
    "\n",
    "losses3 = train(train_dataloader, encoder3, decoder3, 50, learning_rate=0.001, print_every=10)\n",
    "\n",
    "encoder3.eval()\n",
    "decoder3.eval()\n",
    "\n",
    "print(\"\\nTest Results (Larger Hidden):\")\n",
    "for sentence in test_sentences:\n",
    "    output_words, _ = evaluate(encoder3, decoder3, sentence, input_lang, output_lang)\n",
    "    print(f\"  {sentence} -> {' '.join(output_words)}\")"
   ],
   "id": "d615f6a3030be99c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT 4: More Training Epochs (100)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "encoder4 = EncoderRNN(input_lang.n_words, 128).to(device)\n",
    "decoder4 = AttnDecoderRNN(128, output_lang.n_words).to(device)\n",
    "\n",
    "losses4 = train(train_dataloader, encoder4, decoder4, 100, learning_rate=0.001, print_every=20)\n",
    "\n",
    "encoder4.eval()\n",
    "decoder4.eval()\n",
    "\n",
    "print(\"\\nTest Results (More Epochs):\")\n",
    "for sentence in test_sentences:\n",
    "    output_words, _ = evaluate(encoder4, decoder4, sentence, input_lang, output_lang)\n",
    "    print(f\"  {sentence} -> {' '.join(output_words)}\")"
   ],
   "id": "63cdaa4156ffeb9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Add Word2Vec loading support\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "def load_word2vec_embeddings(lang: Lang, embedding_file: str, embedding_dim: int = 300) -> Optional[torch.Tensor]:\n",
    "    try:\n",
    "        model = KeyedVectors.load_word2vec_format(embedding_file, binary=True)\n",
    "        print(f\"Loaded Word2Vec model with {len(model.key_to_index)} vectors\")\n",
    "        \n",
    "        embedding_matrix = np.random.randn(lang.n_words, embedding_dim).astype(np.float32) * 0.01\n",
    "        found = 0\n",
    "        for word, idx in lang.word2index.items():\n",
    "            if word in model:\n",
    "                embedding_matrix[idx] = model[word]\n",
    "                found += 1\n",
    "        \n",
    "        print(f\"Found Word2Vec embeddings for {found}/{lang.n_words} words\")\n",
    "        return torch.from_numpy(embedding_matrix)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Word2Vec file not found: {embedding_file}\")\n",
    "        return None\n",
    "\n",
    "# Update experiment code\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT 5: Pretrained GloVe Embeddings\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load GloVe embeddings (adjust path to your GloVe file)\n",
    "input_embeddings = load_pretrained_embeddings(input_lang, 'glove.6B.300d.txt', 128)\n",
    "output_embeddings = load_pretrained_embeddings(output_lang, 'glove.6B.300d.txt', 128)\n",
    "\n",
    "encoder5 = EncoderRNN(input_lang.n_words, 128, pretrained_embeddings=input_embeddings).to(device)\n",
    "decoder5 = AttnDecoderRNN(128, output_lang.n_words, pretrained_embeddings=output_embeddings).to(device)\n",
    "\n",
    "losses5 = train(train_dataloader, encoder5, decoder5, 50, learning_rate=0.001, print_every=10)\n",
    "\n",
    "encoder5.eval()\n",
    "decoder5.eval()\n",
    "\n",
    "print(\"\\nTest Results (GloVe Embeddings):\")\n",
    "for sentence in test_sentences:\n",
    "    output_words, _ = evaluate(encoder5, decoder5, sentence, input_lang, output_lang)\n",
    "    print(f\"  {sentence} -> {' '.join(output_words)}\")"
   ],
   "id": "348c32c0276687b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Relax filtering\n",
    "def filterPair_2(p: List[str]) -> bool:\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# Experiment 6: More Sentences\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT 6: More Sentences\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(32)  # Larger dataset due to relaxed filter\n",
    "\n",
    "encoder6 = EncoderRNN(input_lang.n_words, 128).to(device)\n",
    "decoder6 = AttnDecoderRNN(128, output_lang.n_words).to(device)\n",
    "\n",
    "start_time = time.time()\n",
    "losses6 = train(train_dataloader, encoder6, decoder6, 50, learning_rate=0.001, print_every=10)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "encoder6.eval()\n",
    "decoder6.eval()\n",
    "\n",
    "print(f\"\\nTraining Time: {training_time:.0f} seconds\")\n",
    "print(\"\\nTest Results (More Sentences):\")\n",
    "for sentence in test_sentences:\n",
    "    output_words, _ = evaluate(encoder6, decoder6, sentence, input_lang, output_lang)\n",
    "    print(f\"  {sentence} -> {' '.join(output_words)}\")"
   ],
   "id": "53fa78279c3d7c77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===============================\n",
    "# COMPARISON\n",
    "# ===============================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(losses1, label='Baseline (128 hidden, 1 layer, 50 epochs)')\n",
    "plt.plot(losses2, label='Deep (128 hidden, 2 layers, 50 epochs)')\n",
    "plt.plot(losses3, label='Large (256 hidden, 1 layer, 50 epochs)')\n",
    "plt.plot(losses4, label='More Epochs (128 hidden, 1 layer, 100 epochs)')\n",
    "plt.plot(losses5, label='Pretrained GloVe Embeddings (128 hidden, 1 layer, 50 epochs)')\n",
    "plt.plot(losses6, label='More Sentences (128 hidden, 1 layer, 50 epochs)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison.png', dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nFinal Losses:\")\n",
    "print(f\"  Baseline:     {losses1[-1]:.4f}\")\n",
    "print(f\"  Deep Network: {losses2[-1]:.4f}\")\n",
    "print(f\"  Large Hidden: {losses3[-1]:.4f}\")\n",
    "print(f\"  More Epochs:  {losses4[-1]:.4f}\")\n"
   ],
   "id": "ef0b3aa80a14a98a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"AUTOENCODER EXPERIMENT\")\n",
    "print(\"=\"*70)\n",
    "print(\"Creating autoencoder dataset (input = output)...\")\n",
    "\n",
    "# Create autoencoder dataset\n",
    "_, _, pairs = prepareData('eng', 'fra', True)\n",
    "# auto_pairs = [[p[0], p[0]] for p in prepareData('eng', 'fra', True)[2][:1000]]\n",
    "auto_pairs = [[p[0], p[0]] for p in pairs[2][:1000]]\n",
    "auto_lang = Lang('auto')\n",
    "for pair in auto_pairs:\n",
    "    auto_lang.addSentence(pair[0])\n",
    "\n",
    "print(f\"Autoencoder vocab size: {auto_lang.n_words}\")\n",
    "\n",
    "# Create autoencoder dataloader\n",
    "n = len(auto_pairs)\n",
    "auto_input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "auto_target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "for idx, (inp, tgt) in enumerate(auto_pairs):\n",
    "    inp_ids = [auto_lang.word2index[word] for word in inp.split(' ') if word in auto_lang.word2index]\n",
    "    tgt_ids = [auto_lang.word2index[word] for word in tgt.split(' ') if word in auto_lang.word2index]\n",
    "    inp_ids.append(EOS_token)\n",
    "    tgt_ids.append(EOS_token)\n",
    "    auto_input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "    auto_target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "auto_data = TensorDataset(\n",
    "    torch.LongTensor(auto_input_ids).to(device),\n",
    "    torch.LongTensor(auto_target_ids).to(device)\n",
    ")\n",
    "auto_dataloader = DataLoader(auto_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# Train autoencoder\n",
    "print(\"Training autoencoder...\")\n",
    "auto_encoder = EncoderRNN(auto_lang.n_words, 128).to(device)\n",
    "auto_decoder = AttnDecoderRNN(128, auto_lang.n_words).to(device)\n",
    "\n",
    "auto_losses = train(auto_dataloader, auto_encoder, auto_decoder, 50, learning_rate=0.001, print_every=10)\n",
    "\n",
    "# Save encoder\n",
    "torch.save(auto_encoder.state_dict(), 'auto_encoder.pth')\n",
    "print(\"Saved autoencoder encoder to 'auto_encoder.pth'\")\n",
    "\n",
    "# Evaluate autoencoder\n",
    "auto_encoder.eval()\n",
    "auto_decoder.eval()\n",
    "print(\"\\nAutoencoder Test Results:\")\n",
    "test_sentences = [\n",
    "    'je suis trop fatigue',\n",
    "    'il est tres grand',\n",
    "    'elle est belle'\n",
    "]\n",
    "for sentence in test_sentences:\n",
    "    if all(word in auto_lang.word2index for word in sentence.split(' ')):\n",
    "        output_words, _ = evaluate(auto_encoder, auto_decoder, sentence, auto_lang, auto_lang)\n",
    "        print(f\"  {sentence} -> {' '.join(output_words)}\")\n",
    "    else:\n",
    "        print(f\"  {sentence} -> [Skipped: Unknown words]\")\n",
    "\n",
    "# ===============================\n",
    "# TRANSLATION WITH PRETRAINED ENCODER\n",
    "# ===============================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRANSLATION EXPERIMENT WITH PRETRAINED ENCODER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load translation dataset\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(32, 'eng', 'fra', True)\n",
    "\n",
    "# Initialize and load pretrained encoder\n",
    "translation_encoder = EncoderRNN(auto_lang.n_words, 128).to(device)\n",
    "translation_encoder.load_state_dict(torch.load('auto_encoder.pth'))\n",
    "translation_encoder.eval()  # Freeze encoder\n",
    "\n",
    "# Initialize new decoder\n",
    "translation_decoder = AttnDecoderRNN(128, output_lang.n_words).to(device)\n",
    "\n",
    "# Train only the decoder\n",
    "print(\"Training new decoder for French-to-English translation...\")\n",
    "trans_losses = train(train_dataloader, translation_encoder, translation_decoder, 50, learning_rate=0.001, print_every=10, train_encoder=False)\n",
    "\n",
    "translation_decoder.eval()\n",
    "\n",
    "# Evaluate translation\n",
    "print(\"\\nTranslation Test Results:\")\n",
    "for sentence in test_sentences:\n",
    "    if all(word in input_lang.word2index for word in sentence.split(' ')):\n",
    "        output_words, _ = evaluate(translation_encoder, translation_decoder, sentence, input_lang, output_lang)\n",
    "        print(f\"  {sentence} -> {' '.join(output_words)}\")\n",
    "    else:\n",
    "        print(f\"  {sentence} -> [Skipped: Unknown words]\")\n",
    "\n",
    "# Compute BLEU score\n",
    "bleu_score = evaluate_bleu(translation_encoder, translation_decoder, pairs, input_lang, output_lang)\n",
    "print(f\"\\nBLEU Score (Translation): {bleu_score:.4f}\")\n",
    "\n",
    "# ===============================\n",
    "# BASELINE FOR COMPARISON\n",
    "# ===============================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE EXPERIMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "baseline_encoder = EncoderRNN(input_lang.n_words, 128).to(device)\n",
    "baseline_decoder = AttnDecoderRNN(128, output_lang.n_words).to(device)\n",
    "\n",
    "baseline_losses = train(train_dataloader, baseline_encoder, baseline_decoder, 50, learning_rate=0.001, print_every=10)\n",
    "\n",
    "baseline_encoder.eval()\n",
    "baseline_decoder.eval()\n",
    "\n",
    "print(\"\\nBaseline Test Results:\")\n",
    "for sentence in test_sentences:\n",
    "    if all(word in input_lang.word2index for word in sentence.split(' ')):\n",
    "        output_words, _ = evaluate(baseline_encoder, baseline_decoder, sentence, input_lang, output_lang)\n",
    "        print(f\"  {sentence} -> {' '.join(output_words)}\")\n",
    "    else:\n",
    "        print(f\"  {sentence} -> [Skipped: Unknown words]\")\n",
    "\n",
    "baseline_bleu = evaluate_bleu(baseline_encoder, baseline_decoder, pairs, input_lang, output_lang)\n",
    "print(f\"\\nBLEU Score (Baseline): {baseline_bleu:.4f}\")\n",
    "\n",
    "# ===============================\n",
    "# VISUALIZATION\n",
    "# ===============================\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(auto_losses, label='Autoencoder (French-to-French)')\n",
    "plt.plot(trans_losses, label='Translation with Pretrained Encoder')\n",
    "plt.plot(baseline_losses, label='Baseline (French-to-English)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('autoencoder_comparison.png', dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nFinal Losses:\")\n",
    "print(f\"  Autoencoder: {auto_losses[-1]:.4f}\")\n",
    "print(f\"  Translation with Pretrained Encoder: {trans_losses[-1]:.4f}\")\n",
    "print(f\"  Baseline: {baseline_losses[-1]:.4f}\")"
   ],
   "id": "a0a85246c7a1615c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
